

dispatcher-server {
  host: "localhost"
  host: ${?MASTER_SERVER_HOST}
  port: 9081
  port: ${?MASTER_SERVER_PORT}
  end-point: "http://"${dispatcher-server.host}":"${dispatcher-server.port}
}

slave-id: "slave1"
slave-id: ${?SLAVE_ID}

grpc-timeout: 1second
grpc-timeout: ${?GRPC_TIMEOUT}

join-request-retries: 5
grpc-timeout: ${?JOIN_REQUEST_RETRIES}

grpc-server {
  host: "localhost"
  host: ${?GRPC_SERVER_HOST}
  port: 9084
  port: ${?GRPC_SERVER_PORT}
  end-point: "http://"${grpc-server.host}":"${grpc-server.port}
}

mongodb {
  host: "localhost"
  host: ${?MONGODB_HOST}
  port: 27017
  host: ${?MONGODB_PORT}
  url: "mongodb://"${mongodb.host}":"${mongodb.port}
  database: "mini_platform"
  transactions-collection-name: "transactions"
  operations-collection-name: "transactions"
}

redis {
  host: "localhost"
  host: ${?REDIS_HOST}
  port: 6379
  host: ${?REDIS_PORT}
  url: "redis://"${redis.host}":"${redis.port}
  interactions-key-prefix: "interaction-"
  branches-key-prefix: "branch-"
  fraudsters-key: "fraudsters"
}


kafka {
  bootstrap.servers = "localhost:9092"
  client.id = ""

  # E.g. "org.apache.kafka.clients.producer.internals.DefaultPartitioner"
  partitioner.class = null

  acks = "1"
  buffer.memory = 33554432
  compression.type = "none"
  retries = 0
  max.in.flight.requests.per.connection = 5

  ssl.key.password = null
  ssl.keystore.password = null
  ssl.keystore.location = null
  ssl.truststore.password = null
  ssl.truststore.location = null

  batch.size = 16384
  connections.max.idle.ms = 540000
  linger.ms = 0
  max.block.ms = 60000
  max.request.size = 1048576

  receive.buffer.bytes = 32768
  request.timeout.ms = 40000

  sasl.kerberos.service.name = null
  sasl.mechanism = "GSSAPI"

  security.protocol = "PLAINTEXT"
  send.buffer.bytes = 131072
  ssl.enabled.protocols = "TLSv1.2,TLSv1.1,TLSv1"
  ssl.keystore.type = "JKS"
  ssl.protocol = "TLS"
  ssl.provider = null
  ssl.truststore.type = "JKS"

  reconnect.backoff.ms = 50
  retry.backoff.ms = 100

  metadata.max.age.ms = 300000

  metric.reporters = ""
  metrics.num.samples = 2
  metrics.sample.window.ms = 30000

  # Consumer specific settings
  client.rack = ""
  fetch.min.bytes = 1
  fetch.max.bytes = 52428800
  group.id = "monix-auction-worker-service"
  heartbeat.interval.ms = 3000
  max.partition.fetch.bytes = 1048576
  auto.offset.reset = "latest"
  # Disabled to use back-pressure or manual commits instead
  enable.auto.commit = false
  exclude.internal.topics = true
  receive.buffer.bytes = 65536
  check.crcs = true
  fetch.max.wait.ms = 500
  # Default values for polling
  # See https://cwiki.apache.org/confluence/display/KAFKA/KIP-62%3A+Allow+consumer+to+send+heartbeats+from+a+background+thread
  session.timeout.ms = 10000
  max.poll.records = 500
  max.poll.interval.ms = 300000

  # Monix specific settings

  # Number of requests that KafkaProducerSink
  # can push in parallel
  monix.producer.sink.parallelism = 100
  # Triggers either seekToEnd or seektoBeginning when the observable starts
  # Possible values: end, beginning, no-seek
  monix.observable.seek.onStart = "no-seek"
  # Possible values: sync, async
  monix.observable.commit.type = "sync"
  # Possible values: before-ack, after-ack or no-ack
  monix.observable.commit.order = "after-ack"
}